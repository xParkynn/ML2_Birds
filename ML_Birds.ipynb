{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe26fe16",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b922d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn                # f√ºr nn layers\n",
    "import torch.nn.functional as F       \n",
    "import torch.optim as optim            \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "#\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T   \n",
    "import numpy as np                     \n",
    "import pandas as pd                   \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d50988",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c659348",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectogramDataset(Dataset):\n",
    "    def __init__(self, audio_dir:str, label_to_idx:dict, max_cache_size: int = 5):\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.audio_dir = audio_dir\n",
    "        self.chunk_index_pairs = []\n",
    "        self.cache = OrderedDict()\n",
    "        self.path_to_label = defaultdict(list)\n",
    "        self.max_cache_size = max_cache_size\n",
    "\n",
    "        for label in os.listdir(self.audio_dir):\n",
    "            for file in os.listdir(f'{self.audio_dir}/{label}'):\n",
    "                tensor = torch.load(f\"{self.audio_dir}/{label}/{file}\")\n",
    "                amount_of_chunks = tensor.shape[0]\n",
    "                self.path_to_label[label].append(f'{self.audio_dir}/{label}/{file}')\n",
    "                for n in range(amount_of_chunks):\n",
    "                    self.chunk_index_pairs.append((f'./data/processed_train_audio/{label}/{file}' ,label, n))\n",
    "\n",
    "    def load_cached_tensor(self, file_path):\n",
    "        if file_path in self.cache:\n",
    "            self.cache.move_to_end(file_path)\n",
    "        else:\n",
    "            tensor = torch.load(file_path)\n",
    "            self.cache[file_path] = tensor\n",
    "            if len(self.cache) > self.max_cache_size:\n",
    "                self.cache.popitem(last=False)\n",
    "            return self.cache[file_path]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chunk_index_pairs)\n",
    "    \n",
    "    def __getitem__(self, idx:int):\n",
    "        file_path, label, chunk_index = self.chunk_index_pairs[idx]\n",
    "        tensor = self.load_cached_tensor(file_path)\n",
    "        chunk = tensor[chunk_index]\n",
    "\n",
    "        return chunk, self.label_to_idx[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20c400de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '10', '100', '101', '102', '103', '104', '105', '106']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "metadata = pd.read_csv(\"./data/processed_data.csv\")\n",
    "unique_labels = sorted(metadata[\"primary_label\"].astype(str).unique())\n",
    "label_to_index = {label: idx for idx,label in enumerate(unique_labels)}\n",
    "index_to_label = {idx: label for idx,label in enumerate(unique_labels)}\n",
    "print(list(unique_labels)[:10])\n",
    "#kann auch numerisch sorten theoretisch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71993924",
   "metadata": {},
   "source": [
    "## Create Data-Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10e222fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.1 s, sys: 21 s, total: 23.1 s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "361766"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "audio_dir=\"./data/processed_train_audio\"\n",
    "\n",
    "\n",
    "train_dataset = SpectogramDataset(\n",
    "    audio_dir=audio_dir,\n",
    "    label_to_idx=label_to_index,\n",
    ")\n",
    "\n",
    "\n",
    "training_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7055531",
   "metadata": {},
   "source": [
    "# Base Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96abcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv2d = nn.Conv2d(1,16,kernel_size=3,padding=1)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,16,kernel_size=3,padding=1), #1 nur wenn es wirklich grayscale images sind\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16,32,kernel_size=3,padding=1), # 16 weil wir nochmals die input_size auf 32 erh√∂hen \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 32 * 32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4609fe98",
   "metadata": {},
   "source": [
    "# Backup Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a97cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ChunkedSpectrogramDataset(Dataset):\n",
    "    def __init__(self, tensor_dir: str, label_to_idx: dict):\n",
    "        self.tensor_dir = tensor_dir\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.index_list = []\n",
    "\n",
    "        # üß† Indexstruktur aufbauen: [(label_name, chunk_idx), ...]\n",
    "        for fname in os.listdir(tensor_dir):\n",
    "            if fname.endswith(\".pt\"):\n",
    "                label = fname.replace(\".pt\", \"\")\n",
    "                tensor_path = os.path.join(tensor_dir, fname)\n",
    "                try:\n",
    "                    tensor = torch.load(tensor_path, map_location=\"cpu\")\n",
    "                    n_chunks = tensor.shape[0]\n",
    "                    for i in range(n_chunks):\n",
    "                        self.index_list.append((label, i))\n",
    "                except Exception as e:\n",
    "                    print(f\"Fehler beim Laden von {tensor_path}: {e}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label_name, chunk_idx = self.index_list[idx]\n",
    "        tensor_path = os.path.join(self.tensor_dir, f\"{label_name}.pt\")\n",
    "\n",
    "        try:\n",
    "            # üîÅ Nur dieses eine Label laden\n",
    "            all_chunks = torch.load(tensor_path, map_location=\"cpu\")\n",
    "            chunk = all_chunks[chunk_idx]\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Laden von Chunk {chunk_idx} f√ºr Label {label_name}: {e}\")\n",
    "            chunk = torch.zeros((1, 128, 216))  # Dummy shape anpassen falls n√∂tig\n",
    "            \n",
    "        # üéØ Label-Tensor (One-hot)\n",
    "        label_tensor = torch.zeros(len(self.label_to_idx), dtype=torch.float32)\n",
    "        if label_name in self.label_to_idx:\n",
    "            label_index = self.label_to_idx[label_name]\n",
    "            label_tensor[label_index] = 1.0\n",
    "\n",
    "        return chunk, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b58905",
   "metadata": {},
   "source": [
    "# √úberarbeitetes  ChunkDataset von ino (path issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daa62c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class inoChunkedSpectrogramDataset(Dataset):\n",
    "    def __init__(self, tensor_dir: str, label_to_idx: dict):\n",
    "        self.tensor_dir = tensor_dir\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.index_list = []\n",
    "\n",
    "        # üß† Indexstruktur aufbauen: [(label_name, chunk_idx), ...]\n",
    "        for root, _, files in os.walk(tensor_dir):\n",
    "                for fname in files:\n",
    "                    if fname.endswith(\".pt\"):\n",
    "                        label = fname.replace(\".pt\", \"\")\n",
    "                        tensor_path = os.path.join(root, fname)\n",
    "                        try:\n",
    "                            tensor = torch.load(tensor_path, map_location=\"cpu\")\n",
    "                            n_chunks = tensor.shape[0]\n",
    "                            for i in range(n_chunks):\n",
    "                                self.index_list.append((label, i))\n",
    "                        except Exception as e:\n",
    "                            print(f\"Fehler beim Laden von {tensor_path}: {e}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label_name, chunk_idx = self.index_list[idx]\n",
    "        tensor_path = os.path.join(self.tensor_dir, f\"{label_name}.pt\")\n",
    "\n",
    "        try:\n",
    "            # üîÅ Nur dieses eine Label laden\n",
    "            all_chunks = torch.load(tensor_path, map_location=\"cpu\")\n",
    "            chunk = all_chunks[chunk_idx]\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Laden von Chunk {chunk_idx} f√ºr Label {label_name}: {e}\")\n",
    "            chunk = torch.zeros((1, 128, 216))  # Dummy shape anpassen falls n√∂tig\n",
    "            \n",
    "        # üéØ Label-Tensor (One-hot)\n",
    "        label_tensor = torch.zeros(len(self.label_to_idx), dtype=torch.float32)\n",
    "        if label_name in self.label_to_idx:\n",
    "            label_index = self.label_to_idx[label_name]\n",
    "            label_tensor[label_index] = 1.0\n",
    "\n",
    "        return chunk, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478682e6",
   "metadata": {},
   "source": [
    "# DataLoader for ChunkSpectogramDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f31545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crbtan1', '48124', '476537', '66016', '42087', 'crcwoo1', 'blcant4', '787625', '24292', '21116', '46010', 'compau', 'gybmar', '50186', 'brtpar1', 'whwswa1', '52884', '868458', 'royfly1', 'cinbec1', '963335', '476538', 'leagre', 'greibi1', 'ampkin1', 'plukit1', 'greani1', 'savhaw1', '22333', 'rosspo1', 'yelori1', 'recwoo1', 'rutjac1', '41970', 'baymac', 'butsal1', '555142', 'grnkin', '21038', '41778', 'cotfly1', 'yebfly1', 'bafibi1', 'amakin1', '548639', 'greegr', '66531', 'blbgra1', 'norscr1', 'spepar1', 'y00678', '24322', 'smbani', '1139490', '65349', 'watjac1', '65962', '21211', 'laufal1', '67252', '65336', 'strcuc1', '66578', 'spbwoo1', 'amekes', 'whttro1', 'trokin', 'yehbla2', 'blkvul', 'grekis', 'ywcpar', 'sahpar1', '134933', 'fotfly', 'strfly1', '42113', 'speowl1', 'gohman1', '566513', 'blcjay1', '715170', 'rtlhum', 'bucmot3', 'chbant1', '47067', 'stbwoo2', '135045', 'whtdov', 'sobtyr1', 'turvul', 'piwtyr1', 'cregua1', 'whbman1', '1462711', '22973', 'rugdov', 'yehcar1', 'cargra1', '523060', 'bobfly1', 'blctit1', 'trsowl', 'paltan1', 'bicwre1', 'rufmot1', '65448', '24272', 'piepuf1', 'yebsee1', 'pavpig2', '41663', 'anhing', 'bbwduc', 'chfmac1', 'cocwoo1', 'thlsch3', 'rinkin1', 'snoegr', 'bkcdon', 'purgal2', 'bobher1', 'bkmtou1', 'bugtan', 'rebbla1', 'orcpar', 'gretin1', '1462737', '1564122', 'linwoo1', 'pirfly1', '65373', 'olipic1', 'soulap1', '126247', 'thbeup1', 'rubsee1', '81930', 'socfly1', 'blhpar1', '67082', 'grasal4', 'bubcur1', '65547', 'roahaw', '65344', '1192948', 'tbsfin1', 'colara1', 'neocor', '1194042', '64862', 'labter1', '714022', 'palhor2', 'yercac1', 'plctan1', 'plbwoo1', 'compot1', 'colcha1', 'mastit1', 'strowl1', 'tropar', 'banana', 'bubwre1', 'shtfly1', 'grepot1', 'cocher1', 'yeofly1', 'whmtyr1', 'solsan', 'whfant1', 'blbwre1', '517119', 'grysee1', 'srwswa1', 'creoro1', 'ragmac1', 'woosto', 'grbhaw1', 'eardov1', 'littin1', 'secfly1', 'yebela1', 'shghum1', 'yecspi2', 'babwar', 'whbant1', '42007', '1346504', 'verfly', '65419', 'saffin', 'rumfly1', '555086', 'cattyr', '528041', 'strher', 'blchaw1', 'gycwor1', 'wbwwre1', 'crebob1', 'yectyr1', '22976', '66893', 'ruther1', 'rutpuf1']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"./data/processed_train_audio/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b060cd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.inoChunkedSpectrogramDataset object at 0x14d2ae090>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "361766"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "metadata = pd.read_csv(\"./data/processed_data.csv\")\n",
    "unique_labels = sorted(metadata[\"primary_label\"].astype(str).unique())\n",
    "label_to_idx = {label: idx for idx,label in enumerate(unique_labels)}\n",
    "\n",
    "tensor_dir = \"./data/processed_train_audio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f7111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset_chunk = inoChunkedSpectrogramDataset(\n",
    "    tensor_dir=tensor_dir,\n",
    "    label_to_idx=label_to_idx\n",
    ")\n",
    "print(train_dataset_chunk)\n",
    "len(train_dataset_chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c7523cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_chunk = DataLoader(train_dataset_chunk, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b931e2b4",
   "metadata": {},
   "source": [
    "# Train Loop inoChunkedSpectogramDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f946f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "INIT_LR = 0.0005\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2965946",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in EPOCHS:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35904da2",
   "metadata": {},
   "source": [
    "# Map von id to name f√ºr die Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e939abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1139490', 'Ragoniella pulchella'), ('1192948', 'Oxyprora surinamensis'), ('1194042', 'Copiphora colombiae'), ('126247', 'Spotted Foam-nest Frog'), ('1346504', 'Neoconocephalus brachypterus')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "taxonomy_df = pd.read_csv(\"./data/taxonomy.csv\")\n",
    "\n",
    "id_to_name = {}\n",
    "for index, row in taxonomy_df.iterrows():\n",
    "    primary_label = row[\"primary_label\"]\n",
    "    common_name = row[\"common_name\"] \n",
    "    id_to_name[primary_label] = common_name\n",
    "\n",
    "#f√ºr die visualisierung sp√§ter \n",
    "\n",
    "print(list(id_to_name.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6531db48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
