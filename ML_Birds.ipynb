{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe26fe16",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b922d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn                # f√ºr nn layers\n",
    "import torch.nn.functional as F       \n",
    "import torch.optim as optim            \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "#\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T   \n",
    "import numpy as np                     \n",
    "import pandas as pd                   \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d50988",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c659348",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectogramDataset(Dataset):\n",
    "    def __init__(self, audio_dir:str, label_to_idx:dict, max_cache_size: int = 5):\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.audio_dir = audio_dir\n",
    "        self.chunk_index_pairs = []\n",
    "        self.cache = OrderedDict()\n",
    "        self.path_to_label = defaultdict(list)\n",
    "        self.max_cache_size = max_cache_size\n",
    "\n",
    "        for label in os.listdir(self.audio_dir):\n",
    "            for file in os.listdir(f'{self.audio_dir}/{label}'):\n",
    "                tensor = torch.load(f\"{self.audio_dir}/{label}/{file}\")\n",
    "                amount_of_chunks = tensor.shape[0]\n",
    "                self.path_to_label[label].append(f'{self.audio_dir}/{label}/{file}')\n",
    "                for n in range(amount_of_chunks):\n",
    "                    self.chunk_index_pairs.append((f'./data/processed_train_audio/{label}/{file}' ,label, n))\n",
    "\n",
    "    def load_cached_tensor(self, file_path):\n",
    "        if file_path in self.cache:\n",
    "            self.cache.move_to_end(file_path)\n",
    "        else:\n",
    "            tensor = torch.load(file_path)\n",
    "            self.cache[file_path] = tensor\n",
    "            if len(self.cache) > self.max_cache_size:\n",
    "                self.cache.popitem(last=False)\n",
    "            return self.cache[file_path]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chunk_index_pairs)\n",
    "    \n",
    "    def __getitem__(self, idx:int):\n",
    "        file_path, label, chunk_index = self.chunk_index_pairs[idx]\n",
    "        tensor = self.load_cached_tensor(file_path)\n",
    "        chunk = tensor[chunk_index]\n",
    "\n",
    "        return chunk, self.label_to_idx[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c400de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '10', '100', '101', '102', '103', '104', '105', '106']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "metadata = pd.read_csv(\"./data/processed_data.csv\")\n",
    "unique_labels = sorted(metadata[\"primary_label\"].astype(str).unique())\n",
    "label_to_index = {label: idx for idx,label in enumerate(unique_labels)}\n",
    "index_to_label = {idx: label for idx,label in enumerate(unique_labels)}\n",
    "print(list(unique_labels)[:10])\n",
    "#kann auch numerisch sorten theoretisch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71993924",
   "metadata": {},
   "source": [
    "## Create Data-Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e222fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.98 s, sys: 20.7 s, total: 22.6 s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "audio_dir=\"./data/processed_train_audio\"\n",
    "\n",
    "\n",
    "train_dataset = SpectogramDataset(\n",
    "    audio_dir=audio_dir,\n",
    "    label_to_idx=label_to_index,\n",
    ")\n",
    "\n",
    "training_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7055531",
   "metadata": {},
   "source": [
    "# Base Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96abcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv2d = nn.Conv2d(1,16,kernel_size=3,padding=1)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,16,kernel_size=3,padding=1), #1 nur wenn es wirklich grayscale images sind\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16,32,kernel_size=3,padding=1), # 16 weil wir nochmals die input_size auf 32 erh√∂hen \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 32 * 32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4609fe98",
   "metadata": {},
   "source": [
    "# Backup Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32a97cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ChunkedSpectrogramDataset(Dataset):\n",
    "    def __init__(self, tensor_dir: str, label_to_idx: dict):\n",
    "        self.tensor_dir = tensor_dir\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.index_list = []\n",
    "\n",
    "        # üß† Indexstruktur aufbauen: [(label_name, chunk_idx), ...]\n",
    "        for fname in os.listdir(tensor_dir):\n",
    "            if fname.endswith(\".pt\"):\n",
    "                label = fname.replace(\".pt\", \"\")\n",
    "                tensor_path = os.path.join(tensor_dir, fname)\n",
    "                try:\n",
    "                    tensor = torch.load(tensor_path, map_location=\"cpu\")\n",
    "                    n_chunks = tensor.shape[0]\n",
    "                    for i in range(n_chunks):\n",
    "                        self.index_list.append((label, i))\n",
    "                except Exception as e:\n",
    "                    print(f\"Fehler beim Laden von {tensor_path}: {e}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label_name, chunk_idx = self.index_list[idx]\n",
    "        tensor_path = os.path.join(self.tensor_dir, f\"{label_name}.pt\")\n",
    "\n",
    "        try:\n",
    "            # üîÅ Nur dieses eine Label laden\n",
    "            all_chunks = torch.load(tensor_path, map_location=\"cpu\")\n",
    "            chunk = all_chunks[chunk_idx]\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Laden von Chunk {chunk_idx} f√ºr Label {label_name}: {e}\")\n",
    "            chunk = torch.zeros((1, 128, 216))  # Dummy shape anpassen falls n√∂tig\n",
    "            \n",
    "        # üéØ Label-Tensor (One-hot)\n",
    "        label_tensor = torch.zeros(len(self.label_to_idx), dtype=torch.float32)\n",
    "        if label_name in self.label_to_idx:\n",
    "            label_index = self.label_to_idx[label_name]\n",
    "            label_tensor[label_index] = 1.0\n",
    "\n",
    "        return chunk, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e939abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1139490', 'Ragoniella pulchella'), ('1192948', 'Oxyprora surinamensis'), ('1194042', 'Copiphora colombiae'), ('126247', 'Spotted Foam-nest Frog'), ('1346504', 'Neoconocephalus brachypterus')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "taxonomy_df = pd.read_csv(\"./data/taxonomy.csv\")\n",
    "\n",
    "id_to_name = {}\n",
    "for index, row in taxonomy_df.iterrows():\n",
    "    primary_label = row[\"primary_label\"]\n",
    "    common_name = row[\"common_name\"] \n",
    "    id_to_name[primary_label] = common_name\n",
    "\n",
    "#f√ºr die visualisierung sp√§ter \n",
    "\n",
    "print(list(id_to_name.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6531db48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
