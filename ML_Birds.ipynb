{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b922d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn                # für nn layers\n",
    "import torch.nn.functional as F       \n",
    "import torch.optim as optim            \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "#\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T   \n",
    "import numpy as np                     \n",
    "import pandas as pd                   \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "123f5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(\"ML2_Birds/processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba8ecdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>type</th>\n",
       "      <th>filename</th>\n",
       "      <th>rating</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['']</td>\n",
       "      <td>['']</td>\n",
       "      <td>1139490/CSA36385.ogg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.3206</td>\n",
       "      <td>-73.7128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>['']</td>\n",
       "      <td>['']</td>\n",
       "      <td>1139490/CSA36389.ogg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.3206</td>\n",
       "      <td>-73.7128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>['']</td>\n",
       "      <td>['']</td>\n",
       "      <td>1192948/CSA36358.ogg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.3791</td>\n",
       "      <td>-73.7313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>['']</td>\n",
       "      <td>['']</td>\n",
       "      <td>1192948/CSA36366.ogg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2800</td>\n",
       "      <td>-73.8582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>['']</td>\n",
       "      <td>['']</td>\n",
       "      <td>1192948/CSA36373.ogg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.3791</td>\n",
       "      <td>-73.7313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   primary_label secondary_labels  type              filename  rating  \\\n",
       "0              0             ['']  ['']  1139490/CSA36385.ogg     0.0   \n",
       "1              0             ['']  ['']  1139490/CSA36389.ogg     0.0   \n",
       "2              1             ['']  ['']  1192948/CSA36358.ogg     0.0   \n",
       "3              1             ['']  ['']  1192948/CSA36366.ogg     0.0   \n",
       "4              1             ['']  ['']  1192948/CSA36373.ogg     0.0   \n",
       "\n",
       "   latitude  longitude  \n",
       "0    7.3206   -73.7128  \n",
       "1    7.3206   -73.7128  \n",
       "2    7.3791   -73.7313  \n",
       "3    7.2800   -73.8582  \n",
       "4    7.3791   -73.7313  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeb91d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28564 entries, 0 to 28563\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   primary_label     28564 non-null  int64  \n",
      " 1   secondary_labels  28564 non-null  object \n",
      " 2   type              28564 non-null  object \n",
      " 3   filename          28564 non-null  object \n",
      " 4   rating            28564 non-null  float64\n",
      " 5   latitude          27755 non-null  float64\n",
      " 6   longitude         27755 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(3)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b81daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader #instanzen verarbeitung \n",
    "import pandas as pd # df frame erstellung \n",
    "import os\n",
    "import ast # zum parsen\n",
    "from PIL import Image \n",
    "from torchvision import transforms # Für Bild-Transformationen\n",
    "\n",
    "metadata = data\n",
    "spectogramm = \"Data_BIRDCLEF/birdclef-2025/train_audio\"\n",
    "\n",
    "class SpectogramDataset(Dataset):\n",
    "    def __init__(self, metadata_df:pd.DataFrame, audio_dir:str, label_to_idx:dict, transform):\n",
    "        self.metadata_df = metadata_df\n",
    "        self.audio_dir = audio_dir\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.num_classes = len(label_to_idx)\n",
    "        self.transform = transform\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((128,128)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "            ])\n",
    "        else: \n",
    "            self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata_df)\n",
    "    \n",
    "    def __getitem__(self, idx:int):\n",
    "        row = self.metadata_df.iloc[idx]\n",
    "        ogg_original = row[\"filename\"]\n",
    "        primary_label = str(row[\"primary_label\"])\n",
    "        secondary_labels = str(row[\"secondary_labels\"])\n",
    "\n",
    "        spectogramm, _ = os.path.splitext(ogg_original) #os.path.splitext trennt den Pfad in (root, ext)\n",
    "        spectogramm_file_jpg = spectogramm + \".jpg\" #change to jpeg if it isnt jpg- darf ich nicht vergessen!!!!!!!!!!!\n",
    "\n",
    "        spectogramm_path = os.path.join(self.audio_dir, spectogramm_file_jpg)\n",
    "\n",
    "        try: \n",
    "            spectogram_image = Image.open(spectogramm_path).convert(\"L\") # Bild in Graustufenmodus L laden, da Spektogramme keine Farbkanäle haben sollten\n",
    "        except FileNotFoundError: #Wirft einen Fehler wenn die Datei nicht gefunden wurde\n",
    "            print(f\"Spektogrammdatei nicht gefunden: {spectogramm_path} (Original OGG: {ogg_original}). Rückgabe von DummySample\")\n",
    "            \n",
    "            dummy_array = np.zeros((128,128), dtype=np.uint8) #Werte von 0 (Schwarzes Bild) in shape von den anderne Spektogrammen\n",
    "            dummy_pil = Image.fromarray(dummy_array, mode=\"L\")\n",
    "            dummy_labels = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "            dummy_image_tensor = self.transform(dummy_pil)\n",
    "        \n",
    "            return dummy_image_tensor, dummy_labels\n",
    "\n",
    "\n",
    "        except Exception as e: #Fängt alle anderen Fehler auf die aufkommen \n",
    "            print(f\"Warnung: Fehler beim Laden/Verarbeiten vom Bild: {spectogramm_path}, Fehler: {e}\")\n",
    "            dummy_array = np.zeros((128,128), dtype=np.uint8) #Werte von 0 (Schwarzes Bild)\n",
    "            dummy_pil = Image.fromarray(dummy_array, mode=\"L\")\n",
    "            dummy_labels = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "            dummy_image_tensor = self.transform(dummy_pil)\n",
    "            return dummy_image_tensor, dummy_labels\n",
    "        \n",
    "\n",
    "        label_tensor = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "        #Setzen des Primary labels \n",
    "        if primary_label in self.label_to_idx:\n",
    "            label_tensor[self.label_to_idx[primary_label]] = 1.0\n",
    "\n",
    "        #Secondary label muss geparsed d.h aus \"[123, 123]\" wird [123, 123] werden, deswegen ast\n",
    "        try:\n",
    "            secondary_l_list = ast.literal_eval(secondary_labels)\n",
    "            if isinstance(secondary_l_list, list): #check up ob ast wirklich eine liste ausgegeben hat \n",
    "                for sec in secondary_l_list:\n",
    "                    if sec in self.label_to_idx:\n",
    "                        label_tensor[self.label_to_idx[sec]] = 1.0\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        spectogramm_tensor = self.transform(spectogram_image)\n",
    "        return spectogramm_tensor, label_tensor\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c659348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader #instanzen verarbeitung \n",
    "import pandas as pd # df frame erstellung \n",
    "import os\n",
    "import ast # zum parsen\n",
    "from PIL import Image \n",
    "from torchvision import transforms # Für Bild-Transformationen\n",
    "\n",
    "metadata = data\n",
    "spectogramm = \"Data_BIRDCLEF/birdclef-2025/train_audio\"\n",
    "\n",
    "class SpectogramDataset(Dataset):\n",
    "    def __init__(self, metadata_df:pd.DataFrame, audio_dir:str, label_to_idx:dict, transform):\n",
    "        self.metadata_df = metadata_df\n",
    "        self.audio_dir = audio_dir\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.num_classes = len(label_to_idx)\n",
    "        self.transform = transform\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((128,128)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "            ])\n",
    "        else: \n",
    "            self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata_df)\n",
    "    \n",
    "    def __getitem__(self, idx:int):\n",
    "        row = self.metadata_df.iloc[idx]\n",
    "        ogg_original = row[\"filename\"]\n",
    "        primary_label = str(row[\"primary_label\"])\n",
    "        secondary_labels = str(row[\"secondary_labels\"])\n",
    "\n",
    "        spectogramm, _ = os.path.splitext(ogg_original) #os.path.splitext trennt den Pfad in (root, ext)\n",
    "        spectogramm_file_jpg = spectogramm + \".jpg\" #change to jpeg if it isnt jpg- darf ich nicht vergessen!!!!!!!!!!!\n",
    "\n",
    "        spectogramm_path = os.path.join(self.audio_dir, spectogramm_file_jpg)\n",
    "\n",
    "        try: \n",
    "            spectogram_image = Image.open(spectogramm_path).convert(\"L\") # Bild in Graustufenmodus L laden, da Spektogramme keine Farbkanäle haben sollten\n",
    "        except FileNotFoundError: #Wirft einen Fehler wenn die Datei nicht gefunden wurde\n",
    "            print(f\"Spektogrammdatei nicht gefunden: {spectogramm_path} (Original OGG: {ogg_original}). Rückgabe von DummySample\")\n",
    "            \n",
    "            dummy_array = np.zeros((128,128), dtype=np.uint8) #Werte von 0 (Schwarzes Bild) in shape von den anderne Spektogrammen\n",
    "            dummy_pil = Image.fromarray(dummy_array, mode=\"L\")\n",
    "            dummy_labels = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "            dummy_image_tensor = self.transform(dummy_pil)\n",
    "        \n",
    "            return dummy_image_tensor, dummy_labels\n",
    "\n",
    "\n",
    "        except Exception as e: #Fängt alle anderen Fehler auf die aufkommen \n",
    "            print(f\"Warnung: Fehler beim Laden/Verarbeiten vom Bild: {spectogramm_path}, Fehler: {e}\")\n",
    "            dummy_array = np.zeros((128,128), dtype=np.uint8) #Werte von 0 (Schwarzes Bild)\n",
    "            dummy_pil = Image.fromarray(dummy_array, mode=\"L\")\n",
    "            dummy_labels = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "            dummy_image_tensor = self.transform(dummy_pil)\n",
    "            return dummy_image_tensor, dummy_labels\n",
    "        \n",
    "\n",
    "        label_tensor = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "        #Setzen des Primary labels \n",
    "        if primary_label in self.label_to_idx:\n",
    "            label_tensor[self.label_to_idx[primary_label]] = 1.0\n",
    "\n",
    "        #Secondary label muss geparsed d.h aus \"[123, 123]\" wird [123, 123] werden, deswegen ast\n",
    "        try:\n",
    "            secondary_l_list = ast.literal_eval(secondary_labels)\n",
    "            if isinstance(secondary_l_list, list): #check up ob ast wirklich eine liste ausgegeben hat \n",
    "                for sec in secondary_l_list:\n",
    "                    if sec in self.label_to_idx:\n",
    "                        label_tensor[self.label_to_idx[sec]] = 1.0\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        spectogramm_tensor = self.transform(spectogram_image)\n",
    "        return spectogramm_tensor, label_tensor\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c400de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '10', '100', '101', '102', '103', '104', '105', '106']\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"ML2_Birds/processed_data.csv\")\n",
    "unique_labels = sorted(metadata[\"primary_label\"].astype(str).unique())\n",
    "label_to_index = {label: idx for idx,label in enumerate(unique_labels)}\n",
    "index_to_label = {idx: label for idx,label in enumerate(unique_labels)}\n",
    "print(list(unique_labels)[:10])\n",
    "#kann auch numerisch sorten theoretisch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e939abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1139490', 'Ragoniella pulchella'), ('1192948', 'Oxyprora surinamensis'), ('1194042', 'Copiphora colombiae'), ('126247', 'Spotted Foam-nest Frog'), ('1346504', 'Neoconocephalus brachypterus')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "taxonomy_df = pd.read_csv(\"Data_BIRDCLEF/birdclef-2025/taxonomy.csv\")\n",
    "\n",
    "id_to_name = {}\n",
    "for index, row in taxonomy_df.iterrows():\n",
    "    primary_label = row[\"primary_label\"]\n",
    "    common_name = row[\"common_name\"] \n",
    "    id_to_name[primary_label] = common_name\n",
    "\n",
    "#für die visualisierung später \n",
    "\n",
    "print(list(id_to_name.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d2dd03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>type</th>\n",
       "      <th>filename</th>\n",
       "      <th>rating</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14604</th>\n",
       "      <td>134</td>\n",
       "      <td>['strcuc1', 'socfly1', 'whtdov', 'yeofly1']</td>\n",
       "      <td>['song']</td>\n",
       "      <td>pirfly1/XC333930.ogg</td>\n",
       "      <td>3.5</td>\n",
       "      <td>15.5927</td>\n",
       "      <td>-92.8492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25900</th>\n",
       "      <td>190</td>\n",
       "      <td>['']</td>\n",
       "      <td>['']</td>\n",
       "      <td>whtdov/iNat819333.ogg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5808</td>\n",
       "      <td>-83.3835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16701</th>\n",
       "      <td>149</td>\n",
       "      <td>['']</td>\n",
       "      <td>['call']</td>\n",
       "      <td>rufmot1/XC250538.ogg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0350</td>\n",
       "      <td>-77.3990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5509</th>\n",
       "      <td>84</td>\n",
       "      <td>['']</td>\n",
       "      <td>['call']</td>\n",
       "      <td>bubwre1/XC704163.ogg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-21.7557</td>\n",
       "      <td>-48.8326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7468</th>\n",
       "      <td>97</td>\n",
       "      <td>['']</td>\n",
       "      <td>['song']</td>\n",
       "      <td>compau/XC310847.ogg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.6352</td>\n",
       "      <td>-75.8609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       primary_label                             secondary_labels      type  \\\n",
       "14604            134  ['strcuc1', 'socfly1', 'whtdov', 'yeofly1']  ['song']   \n",
       "25900            190                                         ['']      ['']   \n",
       "16701            149                                         ['']  ['call']   \n",
       "5509              84                                         ['']  ['call']   \n",
       "7468              97                                         ['']  ['song']   \n",
       "\n",
       "                    filename  rating  latitude  longitude  \n",
       "14604   pirfly1/XC333930.ogg     3.5   15.5927   -92.8492  \n",
       "25900  whtdov/iNat819333.ogg     0.0    8.5808   -83.3835  \n",
       "16701   rufmot1/XC250538.ogg     4.0   -1.0350   -77.3990  \n",
       "5509    bubwre1/XC704163.ogg     3.0  -21.7557   -48.8326  \n",
       "7468     compau/XC310847.ogg     5.0    5.6352   -75.8609  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    metadata,\n",
    "    test_size=0.2,\n",
    "    stratify=metadata[\"primary_label\"], #this ensures that we keep the same proportions as we have in the dataset if 900 are a and 100 b we will have the same split in the test and train sets \n",
    "    random_state=42\n",
    ")\n",
    "train_df.head()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e222fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"ML2_Birds/processed_data.csv\")\n",
    "audio_dir=\"Data_BIRDCLEF/birdclef-2025/train_audio\"\n",
    "\n",
    "\n",
    "train_dataset = SpectogramDataset(\n",
    "    metadata_df=train_df,\n",
    "    audio_dir=\"Data_BIRDCLEF/birdclef-2025/train_audio\",\n",
    "    label_to_idx=label_to_index,\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "training_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc40f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHATGPT Version weil meine nicht mehr funktioniert \n",
    "\n",
    "class TensorChunkDataset(Dataset):\n",
    "    def __init__(self, tensor_dir, label_to_idx, transform=None):\n",
    "        self.tensor_dir = tensor_dir\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.num_classes = len(label_to_idx)\n",
    "        self.transform = transform\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((128,128)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "            ])\n",
    "        else: \n",
    "            self.transform = transform\n",
    "\n",
    "        # Build index of (label_str, chunk_idx)\n",
    "        self.samples = []\n",
    "        for file in os.listdir(tensor_dir):\n",
    "            if file.endswith(\".pt\"):\n",
    "                label = file.replace(\".pt\", \"\")\n",
    "                path = os.path.join(tensor_dir, file)\n",
    "                data = torch.load(path)  # Shape: (N, 1, 128, 128)\n",
    "                for i in range(data.shape[0]):\n",
    "                    self.samples.append((label, i))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label, chunk_idx = self.samples[idx]\n",
    "        chunk_path = os.path.join(self.tensor_dir, f\"{label}.pt\")\n",
    "        all_chunks = torch.load(chunk_path)\n",
    "        chunk_tensor = all_chunks[chunk_idx]  # shape: (1, 128, 128)\n",
    "\n",
    "        if self.transform:\n",
    "            chunk_tensor = self.transform(chunk_tensor)\n",
    "\n",
    "        label_tensor = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "        label_tensor[self.label_to_idx[label]] = 1.0\n",
    "\n",
    "        return chunk_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07929de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "\n",
    "labels = sorted([f.replace(\".pt\", \"\") for f in os.listdir(tensor_dir)])\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "tensor_dir = \"Data_BIRDCLEF/birdclef-2025/processed_train_audio\"\n",
    "\n",
    "train_dataset = TensorChunkDataset(\n",
    "    tensor_dir=tensor_dir,\n",
    "    label_to_idx=label_to_index,\n",
    "    transform=None  \n",
    ")\n",
    "\n",
    "training_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96abcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv2d = nn.Conv2d(1,16,kernel_size=3,padding=1)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,16,kernel_size=3,padding=1), #1 nur wenn es wirklich grayscale images sind\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16,32,kernel_size=3,padding=1), # 16 weil wir nochmals die input_size auf 32 erhöhen \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 32 * 32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
