{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./data/train.csv')\n",
    "\n",
    "data.drop(labels=['author', 'license', 'url', 'collection', 'common_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ce422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_dict = os.listdir('./data/train_audio')\n",
    "\n",
    "normalized_labels = dict()\n",
    "label_idx = 0\n",
    "for label in data['primary_label']:\n",
    "    if label in normalized_labels:\n",
    "        continue\n",
    "    else:\n",
    "        normalized_labels[label] = label_idx\n",
    "        label_idx += 1\n",
    "\n",
    "assert len(normalized_labels.keys()) == len(folder_dict)\n",
    "\n",
    "data['primary_label'] = data['primary_label'].map(lambda x: normalized_labels[x])\n",
    "\n",
    "label_to_name = dict()\n",
    "\n",
    "for idx, label in enumerate(data['primary_label']):\n",
    "    try:\n",
    "        name = data[data['primary_label'] == label]['scientific_name'][idx]\n",
    "        if label in label_to_name:\n",
    "            continue\n",
    "        label_to_name[label] = name\n",
    "    except:\n",
    "        print(label)\n",
    "\n",
    "label_to_name\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aadb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop('scientific_name', axis=1, inplace=True)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f2d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('label_to_name.json', 'w') as file:\n",
    "    json.dump(label_to_name, file)\n",
    "\n",
    "data.to_csv('processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "649bc952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "CHUNK_SIZE = 5\n",
    "STRIDE = 5\n",
    "chunk_amount = int(32000*CHUNK_SIZE)\n",
    "stride_amount = int(32000*STRIDE)\n",
    "melspectogram = torchaudio.transforms.MelSpectrogram()\n",
    "amptodb = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "#os.makedirs('./data/processed_train_audio', exist_ok=True)\n",
    "os.makedirs('./data/train_chunks', exist_ok=True)\n",
    "\n",
    "for label in os.listdir('./data/train_audio'):\n",
    "    train_chunks, test_chunks = [], []\n",
    "    files = os.listdir(f'./data/train_audio/{label}')\n",
    "    random.shuffle(files)\n",
    "    splitindex = int(len(files)*0.8)\n",
    "    train_files, test_files = files[:splitindex], files[splitindex:]\n",
    "\n",
    "    for file in train_files:\n",
    "        audio_file, sr = torchaudio.load(f'./data/train_audio/{label}/{file}')\n",
    "              \n",
    "        total_len = audio_file.shape[1]\n",
    "        for i in range(0, total_len - chunk_amount + 1, stride_amount):\n",
    "            chunk = audio_file[:, i:i+chunk_amount]\n",
    "            mel = melspectogram(chunk)\n",
    "            processed_chunk = amptodb(mel)\n",
    "            processed_chunk = (processed_chunk-processed_chunk.mean())/(processed_chunk.std()+1e-9)\n",
    "            train_chunks.append(processed_chunk)\n",
    "\n",
    "    for file in test_files:\n",
    "        audio_file, sr = torchaudio.load(f'./data/train_audio/{label}/{file}')\n",
    "              \n",
    "        total_len = audio_file.shape[1]\n",
    "        for i in range(0, total_len - chunk_amount + 1, stride_amount):\n",
    "            chunk = audio_file[:, i:i+chunk_amount]\n",
    "            mel = melspectogram(chunk)\n",
    "            processed_chunk = amptodb(mel)\n",
    "            processed_chunk = (processed_chunk-processed_chunk.mean())/(processed_chunk.std()+1e-9)\n",
    "            test_chunks.append(processed_chunk)\n",
    "\n",
    "    if len(train_chunks) < 100 or len(test_chunks) < 100:\n",
    "        continue\n",
    "        \n",
    "    if train_chunks and test_chunks:\n",
    "        random.shuffle(train_chunks)\n",
    "        random.shuffle(test_chunks)\n",
    "        if len(train_chunks) > 300:\n",
    "            indices = torch.randperm(len(train_chunks))[:300]\n",
    "            train_chunks = [train_chunks[i.item()] for i in indices]\n",
    "        if len(test_chunks) > 300:\n",
    "            indices = torch.randperm(len(test_chunks))[:300]\n",
    "            test_chunks = [test_chunks[i.item()] for i in indices]\n",
    "        train_tensor = torch.stack(train_chunks)\n",
    "        test_tensor = torch.stack(test_chunks)\n",
    "        train_tensor = F.interpolate(train_tensor, (224,224), mode='bilinear', align_corners=False)\n",
    "        test_tensor = F.interpolate(test_tensor, (224,224), mode='bilinear', align_corners=False)\n",
    "        train_tensor = train_tensor.repeat(1,3,1,1)\n",
    "        test_tensor = test_tensor.repeat(1,3,1,1)\n",
    "        torch.save(train_tensor.to(torch.float16), f'./data/train_chunks/{label}_train.pt')\n",
    "        torch.save(test_tensor.to(torch.float16), f'./data/train_chunks/{label}_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "591dfea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio.transforms as T\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "\n",
    "def apply_augmentation(chunk):\n",
    "    if random.random() < 0.5:\n",
    "        chunk = T.FrequencyMasking(15)(chunk)\n",
    "    if random.random() < 0.5:\n",
    "        chunk = T.TimeMasking(35)(chunk)\n",
    "    return chunk\n",
    "\n",
    "for file in os.listdir('./data/train_chunks'):\n",
    "    if '_test' in file:\n",
    "        continue\n",
    "    augmented_chunks = []\n",
    "    tensor = torch.load(f'./data/train_chunks/{file}')\n",
    "    chunk_amount = tensor.shape[0]\n",
    "    augmented_chunks = []\n",
    "    idx = 0\n",
    "    \n",
    "    iter_counter = defaultdict(int)\n",
    "\n",
    "    while len(augmented_chunks) < 300-chunk_amount:\n",
    "        if iter_counter[idx] < 10:\n",
    "            augmented_chunks.append(apply_augmentation(tensor[idx]))\n",
    "            iter_counter[idx] += 1\n",
    "        idx = (idx + 1) % chunk_amount\n",
    "    if augmented_chunks:\n",
    "        final_tensor = torch.concat((tensor, torch.stack(augmented_chunks)))\n",
    "\n",
    "        torch.save(final_tensor, f'./data/train_chunks/{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fbac5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torchaudio\n",
    "import torch\n",
    "import os\n",
    "\n",
    "CHUNK_SIZE = 5\n",
    "STRIDE = 5\n",
    "chunk_amount = int(32000*CHUNK_SIZE)\n",
    "stride_amount = int(32000*STRIDE)\n",
    "\n",
    "\n",
    "data = dict()\n",
    "\n",
    "#for label in os.listdir('./data/train_audio'):\n",
    "#    for file in os.listdir(f'./data/train_audio/{label}'):\n",
    "#        audio_file, sr = torchaudio.load(f'./data/train_audio/{label}/{file}')        \n",
    "#        total_len = audio_file.shape[1]\n",
    "#        number_of_chunks = 0\n",
    "#        for i in range(0, total_len - chunk_amount + 1, stride_amount):\n",
    "#            number_of_chunks += 1\n",
    "#        data[file[:-4]] = number_of_chunks\n",
    "\n",
    "for file in os.listdir('./data/train_chunks'):\n",
    "    tensor = torch.load(f'./data/train_chunks/{file}')\n",
    "    data[file[:-3]] = tensor.shape[0]\n",
    "\n",
    "with open('./dataset_init.json', 'w') as file:\n",
    "    json.dump(data, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
