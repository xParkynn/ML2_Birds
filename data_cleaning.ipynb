{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./data/train.csv')\n",
    "\n",
    "data.drop(labels=['author', 'license', 'url', 'collection', 'common_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ce422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_dict = os.listdir('./data/train_audio')\n",
    "\n",
    "normalized_labels = dict()\n",
    "label_idx = 0\n",
    "for label in data['primary_label']:\n",
    "    if label in normalized_labels:\n",
    "        continue\n",
    "    else:\n",
    "        normalized_labels[label] = label_idx\n",
    "        label_idx += 1\n",
    "\n",
    "assert len(normalized_labels.keys()) == len(folder_dict)\n",
    "\n",
    "data['primary_label'] = data['primary_label'].map(lambda x: normalized_labels[x])\n",
    "\n",
    "label_to_name = dict()\n",
    "\n",
    "for idx, label in enumerate(data['primary_label']):\n",
    "    try:\n",
    "        name = data[data['primary_label'] == label]['scientific_name'][idx]\n",
    "        if label in label_to_name:\n",
    "            continue\n",
    "        label_to_name[label] = name\n",
    "    except:\n",
    "        print(label)\n",
    "\n",
    "label_to_name\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aadb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop('scientific_name', axis=1, inplace=True)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f2d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('label_to_name.json', 'w') as file:\n",
    "    json.dump(label_to_name, file)\n",
    "\n",
    "data.to_csv('processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cecc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb65c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [18:02<00:00,  5.26s/it]\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "CHUNK_LENGTH=5\n",
    "STRIDE=2.5\n",
    "\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(sample_rate=32000, n_fft=1024)\n",
    "amp_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "\n",
    "def process_chunk(label_path, label):\n",
    "    chunks = []\n",
    "    for file in os.listdir(label_path):\n",
    "        path = f\"{label_path}/{file}\"\n",
    "        audio_file, sr = torchaudio.load(path)\n",
    "        total_len = audio_file.shape[1]\n",
    "        chunk_amount = int(sr * CHUNK_LENGTH)\n",
    "        stride_amount = int(sr*STRIDE)\n",
    "        if total_len < chunk_amount:\n",
    "            continue\n",
    "        for i in range(0, total_len - chunk_amount + 1, stride_amount):\n",
    "            chunk = audio_file[:, i:i+chunk_amount]\n",
    "\n",
    "            mel = mel_transform(chunk)\n",
    "            processed_chunk = amp_transform(mel)\n",
    "            chunks.append(processed_chunk)\n",
    "    if chunks:\n",
    "        torch.save(torch.stack(chunks), f\"./data/processed_train_audio/{label}.pt\")\n",
    "        del chunks, mel, processed_chunk, audio_file\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "for label in tqdm.tqdm(os.listdir('./data/train_soundscapes')):\n",
    "    process_chunk(f'./data/train_audio/{label}', label)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649bc952",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_chunk_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprocessed_data1.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/nlp/lib/python3.12/site-packages/torch/serialization.py:944\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m    943\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m--> \u001b[39m\u001b[32m944\u001b[39m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    951\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    952\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/nlp/lib/python3.12/site-packages/torch/serialization.py:1216\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[39m\n\u001b[32m   1214\u001b[39m     storage = storage.cpu()\n\u001b[32m   1215\u001b[39m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1216\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fbac5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del processed_chunk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4478b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
