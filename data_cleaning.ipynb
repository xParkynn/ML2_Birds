{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./data/train.csv')\n",
    "\n",
    "data.drop(labels=['author', 'license', 'url', 'collection', 'common_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ce422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_dict = os.listdir('./data/train_audio')\n",
    "\n",
    "normalized_labels = dict()\n",
    "label_idx = 0\n",
    "for label in data['primary_label']:\n",
    "    if label in normalized_labels:\n",
    "        continue\n",
    "    else:\n",
    "        normalized_labels[label] = label_idx\n",
    "        label_idx += 1\n",
    "\n",
    "assert len(normalized_labels.keys()) == len(folder_dict)\n",
    "\n",
    "data['primary_label'] = data['primary_label'].map(lambda x: normalized_labels[x])\n",
    "\n",
    "label_to_name = dict()\n",
    "\n",
    "for idx, label in enumerate(data['primary_label']):\n",
    "    try:\n",
    "        name = data[data['primary_label'] == label]['scientific_name'][idx]\n",
    "        if label in label_to_name:\n",
    "            continue\n",
    "        label_to_name[label] = name\n",
    "    except:\n",
    "        print(label)\n",
    "\n",
    "label_to_name\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aadb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop('scientific_name', axis=1, inplace=True)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f2d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('label_to_name.json', 'w') as file:\n",
    "    json.dump(label_to_name, file)\n",
    "\n",
    "data.to_csv('processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cecc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649bc952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxim/miniforge3/envs/nlp/lib/python3.12/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "import os\n",
    "\n",
    "CHUNK_SIZE = 5\n",
    "STRIDE = 2.5\n",
    "chunk_amount = int(32000*CHUNK_SIZE)\n",
    "stride_amount = int(32000*STRIDE)\n",
    "melspectogram = torchaudio.transforms.MelSpectrogram()\n",
    "amptodb = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "for label in os.listdir('./data/train_audio'):\n",
    "    os.makedirs(f'./data/processed_train_audio/{label}', exist_ok=True)\n",
    "    for file in os.listdir(f'./data/train_audio/{label}'):\n",
    "        audio_file, sr = torchaudio.load(f'./data/train_audio/{label}/{file}')        \n",
    "        total_len = audio_file.shape[1]\n",
    "        chunks = []\n",
    "        for i in range(0, total_len - chunk_amount + 1, stride_amount):\n",
    "            chunk = audio_file[:, i:i+chunk_amount]\n",
    "            mel = melspectogram(chunk)\n",
    "            processed_chunk = amptodb(mel)\n",
    "            chunks.append(processed_chunk)\n",
    "        if chunks:\n",
    "            stacked_chunks = torch.stack(chunks)\n",
    "            torch.save(stacked_chunks, f'./data/processed_train_audio/{label}/{file[:-4]}.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fbac5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del processed_chunk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f4478b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128, 313])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.load('./data/processed_train_audio/21116.pt').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257bfa1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e0a6662",
   "metadata": {},
   "source": [
    "# Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb65c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [18:02<00:00,  5.26s/it]\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "CHUNK_LENGTH=5\n",
    "STRIDE=2.5\n",
    "\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(sample_rate=32000, n_fft=1024)\n",
    "amp_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "\n",
    "def process_chunk(label_path, label):\n",
    "    chunks = []\n",
    "    for file in os.listdir(label_path):\n",
    "        path = f\"{label_path}/{file}\"\n",
    "        audio_file, sr = torchaudio.load(path)\n",
    "        total_len = audio_file.shape[1]\n",
    "        chunk_amount = int(sr * CHUNK_LENGTH)\n",
    "        stride_amount = int(sr*STRIDE)\n",
    "        if total_len < chunk_amount:\n",
    "            continue\n",
    "        for i in range(0, total_len - chunk_amount + 1, stride_amount):\n",
    "            chunk = audio_file[:, i:i+chunk_amount]\n",
    "\n",
    "            mel = mel_transform(chunk)\n",
    "            processed_chunk = amp_transform(mel)\n",
    "            chunks.append(processed_chunk)\n",
    "    if chunks:\n",
    "        torch.save(torch.stack(chunks), f\"./data/processed_train_audio/{label}.pt\")\n",
    "        del chunks, mel, processed_chunk, audio_file\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "for label in tqdm.tqdm(os.listdir('./data/train_soundscapes')):\n",
    "    process_chunk(f'./data/train_audio/{label}', label)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
